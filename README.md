AI Video Assistant

ğŸš€ An experimental AI assistant that runs directly in your web browser.
It processes real-time video from your deviceâ€™s camera, recognizes what it sees, and responds to spoken commands.

My long-term vision is to make this the next Siri for AR glasses â€” an intelligent assistant that not only answers questions, but also guides you through complex tasks step by step. Imagine being able to repair your car without any prior mechanical knowledge, just by following AR-based instructions generated by the AI.

âœ¨ Features

ğŸ“· Computer Vision: Processes live video using AI models (YOLO, MediaPipe, OpenAI).

ğŸ™ï¸ Voice Interaction: Understands spoken prompts and responds with voice.

ğŸŒ Web App: Launches in your browser, accessible from desktop or mobile.

ğŸ§  Expandable: Built as a foundation for advanced AR applications.

ğŸ¯ Goals:

Develop an assistant that integrates seamlessly with AR glasses.

Provide step-by-step guidance for complicated tasks (e.g., fixing a car, assembling furniture, troubleshooting electronics).

Create a system where anyone can accomplish expert-level tasks without prior experience.

ğŸ› ï¸ Tech Stack

Python (Flask) for backend

OpenAI API for natural language understanding

YOLO & MediaPipe for vision and detection

SpeechRecognition / TTS for voice interaction

WebRTC / Browser UI for video + mic integration

ğŸš§ Status

This is an early prototype. The current version launches in the browser and can:

Capture video from your device

Analyze it using AI models

Take voice commands and respond

Future work will expand its intelligence, accuracy, and AR integration to help you do complicated tasks.
VIDEO DEMO: https://youtu.be/vp5oYhSXDNc
